# Fashion-MNIST 预处理实验分析报告

## 1. 实验设置概述

- **数据集**: Fashion-MNIST
- **模型**: `SimpleCNN`
- **优化器**: SGD (`lr = 0.001`)
- **训练轮数**: `TRAIN_CONFIG['epochs']`（当前配置为 20）
- **批大小**: `DATA_CONFIG['batch_size']`（当前配置为 64）
- **随机种子**: `TRAIN_CONFIG['random_seed']`（保证实验可复现）
- **比较目标**: 分析不同输入预处理 / 数据增强方案对测试集准确率和训练时间的影响。

预处理实验通过脚本 `compare_preprocessing.py` 实现，所有方案在相同的模型、优化器、超参数下进行训练，仅改变输入预处理方式。

## 2. 预处理方案与实验结果

| 方案           | 预处理描述                          | 测试集准确率 (%) | 训练时间 (s) |
|----------------|-------------------------------------|------------------|--------------|
| NoNormalize    | ToTensor                            | 80.38            | 147.91       |
| Normalize_0.5  | ToTensor + Normalize(0.5, 0.5)      | 82.32            | 218.19       |
| CropFlip_Norm  | RandomCrop + HFlip + Normalize      | 76.39            | 354.45       |
| Affine_Norm    | RandomAffine + Normalize            | 74.62            | 329.62       |
| Erase_Norm     | Normalize + RandomErasing           | 82.27            | 339.80       |

> 说明：数值来自一次完整实验结果，所有方案均在相同的训练配置下运行。

## 3. 结果分析

### 3.1 标准化对性能的影响

- `NoNormalize` (仅 ToTensor) 与 `Normalize_0.5` (ToTensor + Normalize) 对比：
  - 准确率从 **80.38% 提升到 82.32%**；
  - 训练时间有所增加（主要是更多 epoch 内部运算和日志记录开销），但在可接受范围内。
- 结论：
  - 对灰度图像进行 **均值 0.5、方差 0.5 的标准化** 能够改善输入特征的数值分布，使优化过程更稳定，有助于提升测试集泛化性能。

### 3.2 几何增强过强导致性能下降

- `CropFlip_Norm`（随机裁剪 + 水平翻转 + 标准化）：
  - 测试集准确率显著下降到 **76.39%**。
  - 原因分析：
    - Fashion-MNIST 图像尺寸为 28×28，随机裁剪 + padding + 翻转对这么小的图像破坏性较大，容易裁掉关键轮廓或改变物体朝向；
    - 某些类别（如鞋子、裤子）存在明显的左右结构，水平翻转会引入与测试集分布不一致的样本，相当于向训练集中加入噪声；
    - 在有限训练轮数和较小模型容量（SimpleCNN）的条件下，模型难以同时适应过多的几何变化，导致在原始测试集上的性能下降。

- `Affine_Norm`（轻微旋转平移 + 标准化）：
  - 测试集准确率下降到 **74.62%**，为所有方案中最低；
  - 进一步说明较强的几何变换会使训练数据分布与测试集差异过大，模型在学习这些变形的同时，反而降低了在标准测试集上的识别能力。

### 3.3 随机擦除的影响

- `Erase_Norm`（Normalize + RandomErasing）：
  - 测试集准确率为 **82.27%**，与 `Normalize_0.5` 的 **82.32%** 几乎相同；
  - 说明在当前参数设置（擦除概率 p=0.2、图像尺寸 28×28）下，随机擦除作为一种正则化手段：
    - 没有明显提升性能，但也没有破坏整体泛化能力；
    - 可以认为是“轻度正则化”，让模型不过分依赖某一个局部区域的细节。

## 4. 结论与建议

1. **基础标准化是必要且有效的**：
   - 对 Fashion-MNIST 这类灰度图像任务，`ToTensor + Normalize(0.5, 0.5)` 能明显提升模型在测试集上的表现，建议作为默认预处理方案。

2. **几何增强需要根据任务谨慎设计**：
   - 对于 28×28 的小图像，过强的几何变换（随机裁剪、水平翻转、较大角度的仿射变换）容易破坏关键信息，使训练集分布偏离测试集，导致测试准确率下降；
   - 若要使用几何增强，建议：
     - 降低旋转角度和平移幅度；
     - 谨慎使用水平翻转，尤其是在类别本身具有方向性的任务中。

3. **正则化类增强需要结合模型容量和数据规模**：
   - 随机擦除在本实验中效果与单纯标准化接近，既未明显提升也未显著降低性能；
   - 在更大模型或更多训练轮数的设定下，类似 `RandomErasing` 这类方法可能会带来额外收益，值得在后续扩展实验中进一步探索。

4. **实验方法上的总结**：
   - 本实验控制了模型结构、优化器、训练轮数等条件，仅改变预处理策略，使得不同方案的对比具有可解释性和公平性；
   - 通过同时记录测试集准确率和训练时间，可以综合考虑“性能提升”和“计算开销”两个维度，为论文结论提供更完整的依据。

## 5. 后续工作建议

- 尝试 **更弱的几何增强**（如小角度旋转、去掉水平翻转），观察是否能在不过度破坏数据分布的前提下带来小幅收益；
- 在 **更深的网络结构（如 FashionCNN 或 DeeperCNN）** 上重复同样的预处理实验，分析模型容量与数据增强之间的相互作用；
- 将训练/验证曲线（loss 与 accuracy 随 epoch 变化）加入到 TensorBoard 或 Matplotlib 图中，用曲线形态进一步分析哪些预处理方案导致了欠拟合或过拟合。